import numpy as np
import random

eps = np.power(.1, 7)


class randomQuery(object):
    """ Given the final posterior selects the N most likely options to be queried.
        Attr:
            alp(list[str]): list of symbols used by the framework. Can be switched with
                location of images or one hot encoded images.
        Functions:
            reset():
                this selection method is memoryless, therefore this is void\
            update_query():
                updates the querying method and picks the particular query
        """

    def __init__(self, alp, len_query=4):
        self.alp = alp
        self.len_query = len_query

    def reset(self):
        tmp = None

    def update_query(self, p):
        """ with the final belief over the system, updates the querying method and
            generates len_query most likely queries.
            Args:
                p(list[float]): list of probability distribution over the state estimates
                len_query(int): number of queries in the scheduled query
            Return:
                query(list[str]): queries """
        tmp = [i for i in self.alp]
        query = random.sample(tmp, self.len_query)

        return query


class NBestQuery(object):
    """ Given the final posterior selects the N most likely options to be queried.
        Attr:
            alp(list[str]): list of symbols used by the framework. Can be switched with
                location of images or one hot encoded images.
        Functions:
            reset():
                this selection method is memoryless, therefore this is void\
            update_query():
                updates the querying method and picks the particular query
        """

    def __init__(self, alp, len_query=4):
        self.alp = alp
        self.len_query = len_query

    def reset(self):
        tmp = None

    def update_query(self, p):
        """ with the final belief over the system, updates the querying method and
            generates len_query most likely queries.
            Args:
                p(list[float]): list of probability distribution over the state estimates
                len_query(int): number of queries in the scheduled query
            Return:
                query(list[str]): queries """
        tmp = [i for i in self.alp]
        query = best_selection(tmp, p, self.len_query)

        return query


class MomentumQuerying(object):
    """ picks arms in multi armed bandit(MAB) with the momentum reward.
        reward is convex combination of the momentum of a particular query and the
        entropy. given the rewards makes greedy arm selection.
        Attr:
            alp(list[str]): list of symbols used by the framework. Can be switched with
                location of images or one hot encoded images.
            lam(float): in [0,1] convex combination parameter
            gam(float): in [0,1] history decay rate for momentum
            momentum(ndarray[float]): momentum values for each element in the alp
            prob_history(list[list[float]]): probability values for each step in the
                history for each element in the alp
            last_query(list[str]): final query generated by the system
        Functions:
            reset():
                resets the system memory

                """

    def __init__(self, alp, len_query=4, gam=.9, lam=.9):
        self.alp = alp
        self.lam = lam
        self.gam = gam
        self.len_query = len_query
        self.momentum = np.zeros(len(self.alp))
        self.prob_history = []
        self.last_query = []

    def reset(self, lam=.9):
        """ resets the history related items in the query method
            Args:
                lam(float): in [0,1] convex combination parameter """
        self.lam = lam
        self.momentum = np.zeros(len(self.alp))
        self.prob_history = []

    def update_query(self, p):
        """ with the final belief over the system, updates the querying method and
            generates len_query most likely queries.
            Args:
                p(list[float]): list of probability distribution over the state estimates
                len_query(int): number of queries in the scheduled query
            Return:
                query(list[str]): queries """
        tmp = p[:]
        self.prob_history.append(tmp)
        self.update_momentum()

        entropy_term = np.array(tmp) * np.log(tmp) + (1.01 - np.array(tmp)) * (
            np.log(1.01 - np.array(tmp)))
        entropy_term[np.isnan(entropy_term)] = 0
        # TODO: Stupid magic number
        reward = (self.lam - 1) * entropy_term + self.lam * self.momentum
        self.update_lam()

        tmp_alp = [i for i in self.alp]
        tmp_query = best_selection(tmp_alp, reward, self.len_query)

        self.last_query = [i for i in tmp_query]

        return self.last_query

    def update_momentum(self):
        """ momentum is updated with the particular probability history of the system.
            WARNING!: if called twice without a probability update, will update
            momentum using the same information twice """
        if len(self.prob_history) >= 2:
            # only update momentum for previous terms
            idx_prev_query = [self.alp.index(self.last_query[i]) for i in
                              range(len(self.last_query))]
            self.momentum *= self.gam

            for k in idx_prev_query:
                # momentum = current_mass * mass_displacement
                self.momentum[k] += self.prob_history[-1][k] * np.power(10,
                                                                        5) * (
                                            self.prob_history[-1][k] -
                                            self.prob_history[-2][k])

    def update_lam(self):
        """ Handles the handshaking between two objectives. currently just a constant
            shift with number of queries, should be updated logically """
        self.lam = np.max([self.lam - .2, 0])


class MomentumQueryingLog(object):

    def __init__(self, alp, len_query=4, gam=1., lam=1., dlam=.9, shift=0,
                 updateLam=True):
        self.alp = alp
        self.lam = np.float(lam)
        self.dlam = dlam
        self.shift = shift
        self.gam = np.float(gam)
        self.len_query = len_query
        self.updateLam = updateLam
        self.momentum = np.zeros(len(self.alp))
        self.prob_history = []
        self.last_query = []

    def reset(self, lam=1):
        """ resets the history related items in the query method
            Args:
                lam(float): in [0,1] convex combination parameter """
        if self.updateLam:
            self.lam = np.float(lam)

        self.momentum = np.zeros(len(self.alp))
        self.prob_history = []

    def update_query(self, p):
        """ with the final belief over the system, updates the querying method and
            generates len_query most likely queries.
            Args:
                p(list[float]): list of probability distribution over the state estimates
                len_query(int): number of queries in the scheduled query
            Return:
                query(list[str]): queries """
        tmp = p[:]
        self.prob_history.append(tmp)
        self.update_momentum()
        numSeq = len(self.prob_history)

        entropy_term = np.array(tmp) * np.log(tmp + eps) + (
                1.01 - np.array(tmp)) * (np.log(1.01 - np.array(tmp)))
        entropy_term[np.isnan(entropy_term)] = 0

        if numSeq > 1:
            reward = (self.lam - 1) * entropy_term + (
                    self.lam / numSeq) * self.momentum
        else:
            reward = -entropy_term

        if self.updateLam:
            self.update_lam(len(self.prob_history))

        tmp_alp = [i for i in self.alp]
        tmp_query = best_selection(tmp_alp, reward, self.len_query)

        self.last_query = [i for i in tmp_query]

        return self.last_query

    def update_momentum(self):
        """ momentum is updated with the particular probability history of the system.
            WARNING!: if called twice without a probability update, will update
            momentum using the same information twice """
        if len(self.prob_history) >= 2:
            # only update momentum for previous terms
            idx_prev_query = [self.alp.index(self.last_query[i]) for i in
                              range(len(self.last_query))]
            self.momentum *= self.gam

            for k in idx_prev_query:
                # momentum = current_mass * mass_displacement
                new_mom = self.prob_history[-1][k] * (
                        np.log(self.prob_history[-1][k] + eps) - np.log(
                    self.prob_history[-2][k] + eps))
                self.momentum[k] += new_mom

    def update_lam(self, leng=1):
        """ Handles the handshaking between two objectives. currently just a constant
            shift with number of queries, should be updated logically """
        thr = 1
        if leng < 10:
            self.lam = np.max(
                [self.lam - self.dlam * ((leng - self.shift) / thr), 0])
        else:
            self.lam = 0


def best_selection(list_el, val, len_query):
    """ given set of elements and a value function over the set, picks the len_query
        number of elements with the best value.
        Args:
            list_el(list[str]): the set of elements
            val(list[float]): values for the corresponding elements
            len_query(int): number of elements to be picked from the set
        Return:
            query(list[str]): elements from list_el with the best value """
    max_p_val = np.sort(val)[::-1]
    max_p_val = max_p_val[0:len_query]

    query = []
    for idx in range(len_query):
        idx_q = np.where(val == max_p_val[idx])[0][0]
        q = list_el[idx_q]
        val = np.delete(val, idx_q)
        list_el.remove(q)
        query.append(q)

    return query
